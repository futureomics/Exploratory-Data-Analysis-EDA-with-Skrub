# -*- coding: utf-8 -*-
"""Cancer Gene Expression EDA with Skrub.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZPCb6OUhr5RKIF14fiOxesBwB9edfsMG

# **ðŸ§¬ Biological EDA Example with Skrub: Cancer Gene Expression**

"Breast Cancer" dataset (from scikit-learn) and simulate additional categorical metadata (like tissue type, sample site, etc.), then use Skrub to clean and prepare it for analysis.

subscribe https://www.youtube.com/@Bioinformatics_Made_Easy



âœ… Goal:
Load messy biological metadata

Clean and encode categorical data with Skrub

Explore feature relationships
"""

# Step 1: Install packages
!pip install skrub pandas seaborn matplotlib scikit-learn

# Step 2: Load biological dataset (Breast Cancer)
from sklearn.datasets import load_breast_cancer
import pandas as pd
import numpy as np

# Load data
data = load_breast_cancer(as_frame=True)
df = data.frame
df['target'] = data.target

# Simulate biological metadata (messy categorical columns)
np.random.seed(42)
df['sample_origin'] = np.random.choice(['tissue-a', 'Tissue A', 'tissu-a', 'blood', 'serum'], size=len(df))
df['experiment_group'] = np.random.choice(['control', 'treated', None, 'control'], size=len(df))

print(df[['sample_origin', 'experiment_group']].head())

#Step 3: Analyze + Visualize Metadata

# Check missing values
print(df[['sample_origin', 'experiment_group']].isnull().sum())

# Count plot of categories
import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=df, y='sample_origin')
plt.title("Distribution of Sample Origins")
plt.show()

#Step 4: Clean with Skrub
from skrub import TableVectorizer

# Clean & encode categorical + numeric data
vec = TableVectorizer()
X = vec.fit_transform(df[['sample_origin', 'experiment_group', 'mean radius', 'mean texture']])

# X is already a DataFrame, no need to convert
cleaned_df = X
print(cleaned_df.head())

#Step 5: Visual EDA on Encoded Features

# Correlation heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(cleaned_df.corr(), cmap="coolwarm", annot=True)
plt.title("Encoded Feature Correlation (Skrub)")
plt.show()

# PCA for visualization
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
components = pca.fit_transform(cleaned_df)

plt.scatter(components[:, 0], components[:, 1], c=df['target'], cmap='bwr', alpha=0.6)
plt.title("PCA of Encoded Biological Data")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()

# import skrub
from skrub import TableReport

# open skrub TableReport
TableReport(df)

"""âœ… What Skrub Did Here:
Cleaned categorical biological labels like sample_origin (which were inconsistent)

Handled missing data in experiment_group

Transformed everything into numeric vectors for ML or further statistical analysis
"""